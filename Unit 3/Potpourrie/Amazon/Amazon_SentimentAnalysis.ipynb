{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from nltk import bigrams\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# txt_5 = nltk.word_tokenize(' '.join(df_5['reviewText']))\n",
    "# text_dict = Counter(txt_5)\n",
    "# adj_5 = {word:count for word,count in text_dict.items() if is_adjective(word)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file = ('C:\\\\Users\\\\Abe\\\\Data Science Bootcamp\\\\Unit 3\\\\Potpourrie\\\\Amazon\\\\Sports_and_Outdoors_5.json')\n",
    "df = pd.read_json(file, lines=True)\n",
    "\n",
    "df['sentiment'] = df['overall'].isin([4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create column with adjectives only\n",
    "\n",
    "df['adjective'] = df['reviewText'].apply(nltk.word_tokenize)\n",
    "df['adjective'] = df['adjective'].apply(nltk.pos_tag)\n",
    "df['adjective'] = pd.Series([[word for (word,pos) in item if pos == 'JJ'] for item in df['adjective']])\n",
    "df['adjective'] = df['adjective'].apply(' '.join)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = df.sample(frac=.8)\n",
    "df_test = df.drop(df_train.index)\n",
    "\n",
    "keep = ['overall','reviewText','summary','sentiment']\n",
    "df_train = df_train[keep]\n",
    "df_test = df_test[keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Undersampling\n",
    "\n",
    "rating_1_count = df_train[df_train['overall'] == 1].count()[0]\n",
    "\n",
    "df_ss = pd.DataFrame()\n",
    "for num in [1,2,3,4,5]:\n",
    "    df_ss = df_ss.append(df_train[df_train['overall'] == num].sample(n=rating_1_count),ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "review_dict = {}\n",
    "for name, group in df_train.groupby('overall'):\n",
    "    review_dict[name] = nltk.word_tokenize(' '.join(group['summary']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_dict = {}\n",
    "for key,value in review_dict.items():\n",
    "    count_dict[key] = dict(Counter(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_adjective(word):\n",
    "    return nltk.pos_tag([word])[0][1] == 'JJ'\n",
    "\n",
    "final_dict = {}\n",
    "for rating in count_dict:\n",
    "    adj_dict = {}\n",
    "    for word,count in count_dict[rating].items():\n",
    "        if is_adjective(word):\n",
    "            adj_dict[word] = count\n",
    "    final_dict[rating] = adj_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_adj = pd.DataFrame([(k,k1,v1) for k,v in final_dict.items() for k1,v1 in v.items()],\n",
    "                      columns=['rating','adjective','count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overall</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7253</td>\n",
       "      <td>7253</td>\n",
       "      <td>7253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8131</td>\n",
       "      <td>8131</td>\n",
       "      <td>8131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19244</td>\n",
       "      <td>19244</td>\n",
       "      <td>19244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51641</td>\n",
       "      <td>51641</td>\n",
       "      <td>51641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>150801</td>\n",
       "      <td>150801</td>\n",
       "      <td>150801</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         reviewText  summary  sentiment\n",
       "overall                                \n",
       "1              7253     7253       7253\n",
       "2              8131     8131       8131\n",
       "3             19244    19244      19244\n",
       "4             51641    51641      51641\n",
       "5            150801   150801     150801"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.groupby('overall').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for rating, subset in df_adj.groupby('rating'):\n",
    "#     print(subset.sort_values('count',ascending=False)[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_adj_dup = df_adj.drop_duplicates('adjective',keep=False)\n",
    "\n",
    "# for rating,subset in df_adj_dup.groupby('rating'):\n",
    "#     print(subset.sort_values('count',ascending=False)[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# vectorizer = HashingVectorizer(stop_words='english', non_negative=True)\n",
    "# X_train = vectorizer.transform(df_train['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "nb = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "class DenseTransformer(TransformerMixin):\n",
    "    def fit_transform(self, x, y=None, **fitparams):\n",
    "        return self.transform(x)\n",
    "    def fit(self, x, y=None, **fitparams):\n",
    "        return self\n",
    "    def transform(self, x, y=None, **fitparams):\n",
    "        return x.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87691295324548235"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = df_train['summary']\n",
    "X_test = df_test['summary']\n",
    "Y_train= df_train['sentiment']\n",
    "Y_test = df_test['sentiment']\n",
    "\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, ngram_range=(1, 3), stop_words='english')\n",
    "ch2 = SelectKBest(chi2, k=200)\n",
    "transformer = DenseTransformer()\n",
    "nb = GaussianNB()\n",
    "\n",
    "pipeline = Pipeline([('vectorizer',vectorizer),('Kbest',ch2),('transformer',transformer),('nb_model',nb)])\n",
    "pipeline.fit(X_train,Y_train)\n",
    "pipeline.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "0.877351645941\n",
      "[[ 2949  1554]\n",
      " [ 5715 49049]]\n"
     ]
    }
   ],
   "source": [
    "# Grid search parameters\n",
    "\n",
    "for num in [200]:\n",
    "    # Select X and Y\n",
    "    X_train = df_train['summary']\n",
    "    X_test = df_test['summary']\n",
    "    Y_train= df_train['sentiment']\n",
    "    Y_test = df_test['sentiment']\n",
    "    \n",
    "    # Turn the words into vectors\n",
    "    vectorizer = TfidfVectorizer(sublinear_tf=True, ngram_range=(1, 3), stop_words='english')\n",
    "    X_train = vectorizer.fit_transform(X_train)\n",
    "    X_test = vectorizer.transform(X_test)\n",
    "    \n",
    "    # Select K Best features\n",
    "    ch2 = SelectKBest(chi2, k=num)\n",
    "    X_train = ch2.fit_transform(X_train, Y_train)\n",
    "    X_test = ch2.transform(X_test)\n",
    "    \n",
    "    nb_model = nb.fit(X_train.toarray(),Y_train)\n",
    "    # nb.score(X_train.toarray(),Y_train)\n",
    "    \n",
    "    print(num)\n",
    "    print(nb.score(X_test.toarray(),Y_test))\n",
    "    print(confusion_matrix(nb_model.predict(X_test.toarray()), Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Oversampling using SMOTE\n",
    "\n",
    "# sm = SMOTE()\n",
    "# X_train_res, Y_train_res = sm.fit_sample(X_train.toarray(),Y_train)\n",
    "# X_train_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85275110938633636"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.value_counts()[1] / Y_test.value_counts().sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True], dtype=bool)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_review = ['Not the greatest but it works']\n",
    "predict_me = vectorizer.transform(pos_review)\n",
    "predict_me = ch2.transform(predict_me)\n",
    "\n",
    "nb_model.predict(predict_me.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.873723994803\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 2087,   873],\n",
       "       [ 6611, 49696]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "\n",
    "\n",
    "\n",
    "n_estimators = 20\n",
    "svc = BaggingClassifier(SVC(kernel='linear', probability=True, class_weight='balanced'),\n",
    "                        max_samples=1.0 / n_estimators, n_estimators=n_estimators, n_jobs=3)\n",
    "\n",
    "# l_svc = LinearSVC()\n",
    "\n",
    "\n",
    "pipeline = Pipeline([('vectorizer',vectorizer),('Kbest',ch2),('svc',svc)])\n",
    "pipeline.fit(X_train,Y_train)\n",
    "print(pipeline.score(X_test,Y_test))\n",
    "confusion_matrix(pipeline.predict(X_test),Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(svc.score(X_test.toarray(),Y_test))\n",
    "confusion_matrix(svc_model.predict(X_test.toarray(),Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.61033283607156619"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier(max_features=100,\n",
    "                              max_depth=30)\n",
    "tree_model = tree.fit(X_train_res,Y_train_res)\n",
    "tree.score(X_train_res,Y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.863161624513\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1852,  1270],\n",
       "       [ 6840, 49305]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tree.score(X_test.toarray(),Y_test))\n",
    "confusion_matrix(tree_model.predict(X_test.toarray()), Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Try Oversampling the bad review\n",
    "# Remove nouns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
