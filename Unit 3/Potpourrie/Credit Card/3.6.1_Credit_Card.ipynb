{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import (GradientBoostingClassifier, RandomForestClassifier)\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = 'C:\\\\Users\\\\Abe\\\\Data Science Bootcamp\\\\Unit 3\\\\Potpourrie\\\\Credit Card\\\\creditcard.csv'\n",
    "df = pd.read_csv(file)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[284315,      0],\n",
       "       [    70,    422]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(max_depth=10, max_features=30)\n",
    "\n",
    "X = df.drop('Class',axis=1)\n",
    "y = df['Class']\n",
    "\n",
    "tree.fit(X,y)\n",
    "y_predict = tree.predict(X)\n",
    "confusion_matrix(y, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frauds: 492\n"
     ]
    }
   ],
   "source": [
    "# Split the df in 2 groups. One for frauds and one for non frauds\n",
    "frauds = df[df['Class'] == 1]\n",
    "non_frauds = df[~(df['Class'] == 1)]\n",
    "\n",
    "# Set the ratio for non frauds to frauds in the training set\n",
    "non_fraud_multiplier = 1\n",
    "\n",
    "# Create the training df\n",
    "num_frauds = frauds.shape[0]\n",
    "df_train = non_frauds.sample(n=num_frauds*non_fraud_multiplier).append(frauds)\n",
    "\n",
    "# Create X and y from the new training df\n",
    "X_train = df_train.drop('Class',axis=1)\n",
    "y_train = df_train['Class']\n",
    "\n",
    "# Create X and y to try and predict\n",
    "df_test = df.sample(frac=.5)\n",
    "X_predict = df_test.drop('Class',axis=1)\n",
    "y_true = df_test['Class']\n",
    "\n",
    "print ('Frauds: {}'.format(frauds.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[127673,  14497],\n",
       "       [     0,    234]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(max_depth=20, max_features=30)\n",
    "\n",
    "tree.fit(X_train,y_train)\n",
    "y_predict = tree.predict(X_predict)\n",
    "confusion_matrix(y_true, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[127673,  14497],\n",
       "       [     0,    234]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_tree = GradientBoostingClassifier(max_depth=20, \n",
    "                                     max_features=30,\n",
    "                                     n_estimators=1000,\n",
    "                                     loss='deviance')\n",
    "\n",
    "gb_tree.fit(X_train,y_train)\n",
    "y_predict = tree.predict(X_predict)\n",
    "confusion_matrix(y_true, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[137086,   5084],\n",
       "       [     1,    233]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest = RandomForestClassifier(max_depth=20, \n",
    "                                     max_features=30,\n",
    "                                     n_estimators=50,\n",
    "                                     criterion='entropy')\n",
    "\n",
    "forest.fit(X_train,y_train)\n",
    "y_predict = forest.predict(X_predict)\n",
    "confusion_matrix(y_true, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[103737,  38433],\n",
       "       [    84,    150]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighbors = KNeighborsClassifier(n_neighbors=10)\n",
    "\n",
    "neighbors.fit(X_train,y_train)\n",
    "y_predict = neighbors.predict(X_predict)\n",
    "confusion_matrix(y_true, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set the ratio for non frauds to frauds in the training set\n",
    "non_fraud_multiplier = 2\n",
    "\n",
    "# Create the training df\n",
    "num_frauds = frauds.shape[0]\n",
    "df_train = non_frauds.sample(n=num_frauds*non_fraud_multiplier).append(frauds)\n",
    "\n",
    "# Create X and y from the new training df\n",
    "X_train = df_train.drop('Class',axis=1)\n",
    "y_train = df_train['Class']\n",
    "\n",
    "# Create X and y to try and predict\n",
    "df_test = df.sample(frac=.5)\n",
    "X_predict = df_test.drop('Class',axis=1)\n",
    "y_true = df_test['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[133321,   8841],\n",
       "       [     0,    242]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(max_depth=20, max_features=30)\n",
    "\n",
    "tree.fit(X_train,y_train)\n",
    "y_predict = tree.predict(X_predict)\n",
    "confusion_matrix(y_true, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[140736,   1426],\n",
       "       [     1,    241]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest = RandomForestClassifier(max_depth=20, \n",
    "                                     max_features=30,\n",
    "                                     n_estimators=50,\n",
    "                                     criterion='entropy')\n",
    "\n",
    "forest.fit(X_train,y_train)\n",
    "y_predict = forest.predict(X_predict)\n",
    "confusion_matrix(y_true, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for num in np.arange(1,100,10):\n",
    "#     df_train = non_frauds.sample(n=int(round(num_frauds*num,0))).append(frauds)\n",
    "#     X_train = df_train.drop('Class',axis=1)\n",
    "#     y_train = df_train['Class']\n",
    "#     forest.fit(X_train,y_train)\n",
    "#     y_predict = forest.predict(X_predict)\n",
    "#     print(num)\n",
    "#     print(confusion_matrix(y_true, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non Fraud Ratio: 0.5\n",
      "Total Non Frauds: 246\n",
      "Total Type I errors: 24\n",
      "Total Type II errors: 16034\n",
      "----------------------------------------\n",
      "Non Fraud Ratio: 0.52\n",
      "Total Non Frauds: 256\n",
      "Total Type I errors: 15\n",
      "Total Type II errors: 15344\n",
      "----------------------------------------\n",
      "Non Fraud Ratio: 0.54\n",
      "Total Non Frauds: 266\n",
      "Total Type I errors: 21\n",
      "Total Type II errors: 9501\n",
      "----------------------------------------\n",
      "Non Fraud Ratio: 0.56\n",
      "Total Non Frauds: 276\n",
      "Total Type I errors: 22\n",
      "Total Type II errors: 7320\n",
      "----------------------------------------\n",
      "Non Fraud Ratio: 0.5800000000000001\n",
      "Total Non Frauds: 285\n",
      "Total Type I errors: 16\n",
      "Total Type II errors: 8634\n",
      "----------------------------------------\n",
      "Non Fraud Ratio: 0.6000000000000001\n",
      "Total Non Frauds: 295\n",
      "Total Type I errors: 16\n",
      "Total Type II errors: 10643\n",
      "----------------------------------------\n",
      "Non Fraud Ratio: 0.6200000000000001\n",
      "Total Non Frauds: 305\n",
      "Total Type I errors: 12\n",
      "Total Type II errors: 9255\n",
      "----------------------------------------\n",
      "Non Fraud Ratio: 0.6400000000000001\n",
      "Total Non Frauds: 315\n",
      "Total Type I errors: 16\n",
      "Total Type II errors: 9787\n",
      "----------------------------------------\n",
      "Non Fraud Ratio: 0.6600000000000001\n",
      "Total Non Frauds: 325\n",
      "Total Type I errors: 14\n",
      "Total Type II errors: 9606\n",
      "----------------------------------------\n",
      "Non Fraud Ratio: 0.6800000000000002\n",
      "Total Non Frauds: 335\n",
      "Total Type I errors: 13\n",
      "Total Type II errors: 13652\n",
      "----------------------------------------\n",
      "Non Fraud Ratio: 0.7000000000000002\n",
      "Total Non Frauds: 344\n",
      "Total Type I errors: 13\n",
      "Total Type II errors: 6990\n",
      "----------------------------------------\n",
      "Non Fraud Ratio: 0.7200000000000002\n",
      "Total Non Frauds: 354\n",
      "Total Type I errors: 10\n",
      "Total Type II errors: 12589\n",
      "----------------------------------------\n",
      "Non Fraud Ratio: 0.7400000000000002\n",
      "Total Non Frauds: 364\n",
      "Total Type I errors: 13\n",
      "Total Type II errors: 7252\n",
      "----------------------------------------\n",
      "Non Fraud Ratio: 0.7600000000000002\n",
      "Total Non Frauds: 374\n",
      "Total Type I errors: 5\n",
      "Total Type II errors: 19897\n",
      "----------------------------------------\n",
      "Non Fraud Ratio: 0.7800000000000002\n",
      "Total Non Frauds: 384\n",
      "Total Type I errors: 13\n",
      "Total Type II errors: 11531\n",
      "----------------------------------------\n",
      "Non Fraud Ratio: 0.8000000000000003\n",
      "Total Non Frauds: 394\n",
      "Total Type I errors: 10\n",
      "Total Type II errors: 9499\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for num in np.arange(.5,.8,.02):\n",
    "    frauds_train = frauds.sample(frac=num)\n",
    "    df_train = non_frauds.sample(n=frauds_train.shape[0]).append(frauds_train)\n",
    "    X_train = df_train.drop('Class',axis=1)\n",
    "    y_train = df_train['Class']\n",
    "    forest.fit(X_train,y_train)\n",
    "    df_predict = df[~df.index.isin(df_train.index)]\n",
    "    X_predict = df_predict.drop('Class',axis=1)\n",
    "    y_true = df_predict['Class']\n",
    "    y_predict = forest.predict(X_predict)\n",
    "    cnf = confusion_matrix(y_true,y_predict)\n",
    "    total_cnf = np.sum(cnf)\n",
    "    print ('Non Fraud Ratio: {}'.format(num))\n",
    "    print ('Total Non Frauds: {}'.format(df_train.shape[0] - len(frauds_train)))\n",
    "    print ('Total Type I errors: {}'.format(cnf[1][0]))\n",
    "    print ('Total Type II errors: {}'.format(cnf[0][1]))\n",
    "    print ('--'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non Fraud Ratio: 1\n",
      "Total Non Frauds: 394\n",
      "Total Type I errors: 9\n",
      "Total Type II errors: 12138\n",
      "----------------------------------------\n",
      "Non Fraud Ratio: 2\n",
      "Total Non Frauds: 788\n",
      "Total Type I errors: 11\n",
      "Total Type II errors: 3642\n",
      "----------------------------------------\n",
      "Non Fraud Ratio: 3\n",
      "Total Non Frauds: 1182\n",
      "Total Type I errors: 12\n",
      "Total Type II errors: 2010\n",
      "----------------------------------------\n",
      "Non Fraud Ratio: 4\n",
      "Total Non Frauds: 1576\n",
      "Total Type I errors: 12\n",
      "Total Type II errors: 1443\n",
      "----------------------------------------\n",
      "Non Fraud Ratio: 5\n",
      "Total Non Frauds: 1970\n",
      "Total Type I errors: 12\n",
      "Total Type II errors: 1169\n",
      "----------------------------------------\n",
      "Non Fraud Ratio: 6\n",
      "Total Non Frauds: 2364\n",
      "Total Type I errors: 12\n",
      "Total Type II errors: 800\n",
      "----------------------------------------\n",
      "Non Fraud Ratio: 7\n",
      "Total Non Frauds: 2758\n",
      "Total Type I errors: 12\n",
      "Total Type II errors: 567\n",
      "----------------------------------------\n",
      "Non Fraud Ratio: 8\n",
      "Total Non Frauds: 3152\n",
      "Total Type I errors: 12\n",
      "Total Type II errors: 374\n",
      "----------------------------------------\n",
      "Non Fraud Ratio: 9\n",
      "Total Non Frauds: 3546\n",
      "Total Type I errors: 13\n",
      "Total Type II errors: 453\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for num in np.arange(1,10,1):\n",
    "    df_train = non_frauds.sample(n=frauds_train.shape[0]*num).append(frauds_train)\n",
    "    X_train = df_train.drop('Class',axis=1)\n",
    "    y_train = df_train['Class']\n",
    "    forest.fit(X_train,y_train)\n",
    "    df_predict = df[~df.index.isin(df_train.index)]\n",
    "    X_predict = df_predict.drop('Class',axis=1)\n",
    "    y_true = df_predict['Class']\n",
    "    y_predict = forest.predict(X_predict)\n",
    "    cnf = confusion_matrix(y_true,y_predict)\n",
    "    total_cnf = np.sum(cnf)\n",
    "    print ('Non Fraud Ratio: {}'.format(num))\n",
    "    print ('Total Non Frauds: {}'.format(df_train.shape[0] - len(frauds_train)))\n",
    "    print ('Total Type I errors: {}'.format(cnf[1][0]))\n",
    "    print ('Total Type II errors: {}'.format(cnf[0][1]))\n",
    "    print ('--'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[275455,   8516],\n",
       "       [     9,    139]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the df in 2 groups. One for frauds and one for non frauds\n",
    "frauds = df[df['Class'] == 1]\n",
    "non_frauds = df[~(df['Class'] == 1)]\n",
    "\n",
    "# Use 70% of frauds to train and leave the rest for the test\n",
    "frauds_train = frauds.sample(frac=.7)\n",
    "\n",
    "# Create training set by selecting a random sample of non fraud transactions and appending selected frauds from above\n",
    "df_train = non_frauds.sample(n=frauds_train.shape[0]).append(frauds_train)\n",
    "\n",
    "# Set up training sets for X and y and fit the random forest\n",
    "X_train = df_train.drop('Class',axis=1)\n",
    "y_train = df_train['Class']\n",
    "forest.fit(X_train,y_train)\n",
    "\n",
    "# Select all the data left over for the model to predict\n",
    "df_predict = df[~df.index.isin(df_train.index)]\n",
    "X_predict = df_predict.drop('Class',axis=1)\n",
    "y_true = df_predict['Class']\n",
    "\n",
    "# Run the prediction and print out the confusion matrix\n",
    "y_predict = forest.predict(X_predict)\n",
    "confusion_matrix(y_true,y_predict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
